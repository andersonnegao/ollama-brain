# ğŸ¥ DossiÃª de VÃ­deos

Sistema inteligente para anÃ¡lise, transcriÃ§Ã£o e geraÃ§Ã£o automÃ¡tica de dossiÃªs de conteÃºdo de vÃ­deos do YouTube.

## âœ¨ CaracterÃ­sticas

- ğŸ“¹ **ExtraÃ§Ã£o automÃ¡tica de transcriÃ§Ãµes** do YouTube
- ğŸµ **Fallback com Whisper**: se nÃ£o houver transcriÃ§Ã£o oficial, aceita upload de Ã¡udio
- ğŸ§  **AnÃ¡lise com Ollama**: processamento local com modelos de IA (Mistral, Llama, etc)
- ğŸ“‹ **DossiÃª estruturado em Markdown**: resumo executivo, afirmaÃ§Ãµes verificÃ¡veis, pessoas citadas, etc
- ğŸ” **SeguranÃ§a**: autenticaÃ§Ã£o por Bearer token + CORS controlado
- ğŸ¨ **UI moderna**: React/Vite + design escuro responsivo
- âš¡ **RÃ¡pido**: processamento local, sem dependÃªncias externas

## ğŸš€ Quick Start (Local)

### PrÃ©-requisitos

- Docker & Docker Compose (recomendado)
- Ou: Python 3.11+, Node.js 18+, FFmpeg, Ollama

### Com Docker Compose (easiest)

```bash
# 1. Clone o repositÃ³rio
git clone https://github.com/yourusername/ollama-brain.git
cd ollama-brain

# 2. Crie arquivo .env (copie do .env.example)
cp .env.example .env

# 3. Suba os containers (Ollama + FastAPI)
docker-compose up -d

# 4. Em outro terminal, instale e rode o frontend
cd frontend
npm install
npm run dev

# 5. Acesse no navegador
# Frontend: http://localhost:3000
# API: http://localhost:8080
```

### Manualmente (sem Docker)

#### Backend

```bash
# 1. Instale Ollama
# macOS: brew install ollama
# Linux: curl -fsSL https://ollama.ai/install.sh | sh
# Windows: https://ollama.ai/download

# 2. Inicie Ollama e puxe o modelo
ollama serve
# Em outro terminal:
ollama pull mistral:latest

# 3. Instale dependÃªncias Python
cd backend
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

# 4. Rode a API
export API_TOKEN="dev-token"
export OLLAMA_BASE_URL="http://127.0.0.1:11434"
python -m uvicorn api:app --host 0.0.0.0 --port 8080 --reload
```

#### Frontend

```bash
# Em outro terminal
cd frontend
npm install
npm run dev
# Acesse http://localhost:3000
```

## ğŸ“š Estrutura do Projeto

```
ollama-brain/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ api.py              # FastAPI app
â”‚   â”œâ”€â”€ requirements.txt    # DependÃªncias Python
â”‚   â”œâ”€â”€ Dockerfile         # Docker image
â”‚   â””â”€â”€ __init__.py
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx        # App principal
â”‚   â”‚   â”œâ”€â”€ App.css
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ DossierForm.jsx
â”‚   â”‚   â”‚   â”œâ”€â”€ DossierResult.jsx
â”‚   â”‚   â”‚   â””â”€â”€ TokenPrompt.jsx
â”‚   â”‚   â””â”€â”€ main.jsx
â”‚   â”œâ”€â”€ index.html
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ vite.config.js
â”‚   â””â”€â”€ .env.example
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ .env.example
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

## ğŸ”§ ConfiguraÃ§Ã£o (ENV)

### Backend

```env
API_TOKEN=sua-senha-secreta-aqui
OLLAMA_BASE_URL=http://127.0.0.1:11434
OLLAMA_MODEL=mistral:latest
WHISPER_MODEL=base
MAX_UPLOAD_SIZE=209715200    # 200MB
CORS_ORIGINS=http://localhost:3000
ENV=dev
PORT=8080
```

### Frontend

```env
VITE_API_BASE_URL=http://localhost:8080
```

## ğŸ“¡ API Endpoints

### GET /health
Health check da API.

```bash
curl http://localhost:8080/health
```

### POST /dossier
Cria um dossiÃª a partir de uma URL do YouTube.

**Headers:**
```
Authorization: Bearer <API_TOKEN>
Content-Type: multipart/form-data
```

**Form Data:**
- `url` (string, obrigatÃ³rio): URL do YouTube
- `audio` (file, opcional): MP3/M4A/WAV se nÃ£o houver transcriÃ§Ã£o oficial

**Exemplo:**
```bash
curl -X POST http://localhost:8080/dossier \
  -H "Authorization: Bearer seu-token" \
  -F "url=https://www.youtube.com/watch?v=dQw4w9WgXcQ" \
  -F "audio=@seu_audio.mp3"
```

**Response:**
```json
{
  "markdown": "---\ntype: video\n...\n",
  "transcript": "TranscriÃ§Ã£o completa...",
  "meta": {
    "video_id": "dQw4w9WgXcQ",
    "used": "youtube",
    "generated_at": "2026-01-11T10:30:00.000Z",
    "model": "mistral:latest"
  }
}
```

## ğŸŒ Deploy

### Backend â†’ Fly.io

```bash
# 1. Instale fly CLI
# https://fly.io/docs/getting-started/installing-flyctl/

# 2. Crie app no Fly.io
flyctl launch --name dossier-api

# 3. Configure secrets
flyctl secrets set API_TOKEN="sua-senha-segura"
flyctl secrets set CORS_ORIGINS="https://seu-site.netlify.app"

# 4. Configure volume para Ollama (opcional, salva modelos)
flyctl volumes create ollama-data --size 50

# 5. Deploy
flyctl deploy

# 6. Verifique status
flyctl status
```

### Frontend â†’ Netlify

```bash
# 1. Build
cd frontend
npm run build

# 2. No Netlify:
#    - Deploy via Git (GitHub/GitLab)
#    - Build command: npm run build
#    - Publish directory: dist
#    - Env var: VITE_API_BASE_URL=https://seu-app.fly.dev

# 3. Ou deploy manual
npm i -g netlify-cli
netlify deploy --prod --dir=dist
```

## ğŸ” SeguranÃ§a

- **AutenticaÃ§Ã£o**: Token Bearer na header `Authorization`
- **CORS**: Restrito ao domÃ­nio Netlify (configure via `CORS_ORIGINS`)
- **Upload**: Limite de tamanho (default 200MB)
- **Logs**: Apenas meta e erros, nÃ£o loga Ã¡udio/transcriÃ§Ã£o completa
- **Rate limit**: BÃ¡sico por IP (implemente conforme necessÃ¡rio)

## ğŸ“ Exemplo de Uso

### Via Web UI

1. Abra http://localhost:3000
2. Digite seu token (encontre em `.env`)
3. Cole URL do YouTube: `https://www.youtube.com/watch?v=...`
4. (Opcional) Envie arquivo de Ã¡udio
5. Clique "Gerar DossiÃª"
6. Copie o Markdown ou baixe `.md`

### Via API (curl)

```bash
TOKEN="seu-token-aqui"
URL="https://www.youtube.com/watch?v=dQw4w9WgXcQ"

curl -X POST http://localhost:8080/dossier \
  -H "Authorization: Bearer $TOKEN" \
  -F "url=$URL" \
  | jq .markdown > output.md
```

## ğŸ› Troubleshooting

### Erro: "Ollama service unavailable"
- Confirme que Ollama estÃ¡ rodando: `ollama serve`
- Verifique URL: `curl http://127.0.0.1:11434/api/tags`

### Erro: "No transcript found"
- O vÃ­deo pode nÃ£o ter transcriÃ§Ã£o oficial no YouTube
- SoluÃ§Ã£o: envie um arquivo de Ã¡udio (MP3, M4A, WAV)

### Erro: "Token invalid"
- Verifique o `API_TOKEN` em `.env`
- No frontend, o token Ã© salvo em `localStorage`

### LentidÃ£o
- Whisper Ã© pesado: espere ~2 min para Ã¡udio de 1h
- Ollama depende de CPU/RAM: aumente recursos ou troque modelo
- Modelos recomendados por performance: `phi3:latest`, `mistral:7b`, `llama3.1:8b-instruct`

## ğŸ¤ Contribuindo

1. Fork o repo
2. Crie uma branch: `git checkout -b feature/minha-feature`
3. Commit: `git commit -m "Add: minha feature"`
4. Push: `git push origin feature/minha-feature`
5. Abra PR

## ğŸ“„ LicenÃ§a

MIT License - veja [LICENSE](LICENSE) para detalhes

## ğŸ“ Suporte

- Issues: [GitHub Issues](https://github.com/yourusername/ollama-brain/issues)
- DiscussÃµes: [GitHub Discussions](https://github.com/yourusername/ollama-brain/discussions)

---

**Feito com â¤ï¸ por Anderson**
